{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from typing import Tuple, Union, List\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.utils.convert import from_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in kilometers between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians\n",
    "    # lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "    return c * r\n",
    "\n",
    "haversine = np.vectorize(haversine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-74.017931</td>\n",
       "      <td>40.706175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-74.017869</td>\n",
       "      <td>40.706349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-74.017789</td>\n",
       "      <td>40.706519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-74.017690</td>\n",
       "      <td>40.706683</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-74.017574</td>\n",
       "      <td>40.706840</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236253</th>\n",
       "      <td>-73.901365</td>\n",
       "      <td>40.663609</td>\n",
       "      <td>2414372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236254</th>\n",
       "      <td>-73.951336</td>\n",
       "      <td>40.742705</td>\n",
       "      <td>2414375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236255</th>\n",
       "      <td>-73.951368</td>\n",
       "      <td>40.742617</td>\n",
       "      <td>2414376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236256</th>\n",
       "      <td>-73.951404</td>\n",
       "      <td>40.742530</td>\n",
       "      <td>2414377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236257</th>\n",
       "      <td>-73.951443</td>\n",
       "      <td>40.742444</td>\n",
       "      <td>2414378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>236258 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lng        lat       id\n",
       "0      -74.017931  40.706175        0\n",
       "1      -74.017869  40.706349        1\n",
       "2      -74.017789  40.706519        2\n",
       "3      -74.017690  40.706683        3\n",
       "4      -74.017574  40.706840        4\n",
       "...           ...        ...      ...\n",
       "236253 -73.901365  40.663609  2414372\n",
       "236254 -73.951336  40.742705  2414375\n",
       "236255 -73.951368  40.742617  2414376\n",
       "236256 -73.951404  40.742530  2414377\n",
       "236257 -73.951443  40.742444  2414378\n",
       "\n",
       "[236258 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = pd.read_csv('data/road_intersection_nodes.csv')\n",
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.291857</td>\n",
       "      <td>0.710457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.291856</td>\n",
       "      <td>0.710460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.291854</td>\n",
       "      <td>0.710463</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.291852</td>\n",
       "      <td>0.710466</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.291850</td>\n",
       "      <td>0.710468</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lng       lat  id\n",
       "0 -1.291857  0.710457   0\n",
       "1 -1.291856  0.710460   1\n",
       "2 -1.291854  0.710463   2\n",
       "3 -1.291852  0.710466   3\n",
       "4 -1.291850  0.710468   4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert decimals to radiands\n",
    "nodes_df[['lng', 'lat']] = nodes_df[['lng', 'lat']].apply(np.vectorize(radians))\n",
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7106174200098879, -1.290224335366838)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing center of region\n",
    "lat_center, lng_center = nodes_df.lat.mean(), nodes_df.lng.mean()\n",
    "lat_center, lng_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due computational complexity, I consider only region with a radius of RADIUS around (lat_center, lng_center)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADIUS = 8\n",
    "\n",
    "obs_nodes_df = nodes_df[haversine(lng_center, lat_center, nodes_df.lng, nodes_df.lat) <= RADIUS]\n",
    "obs_nodes_set = set(obs_nodes_df.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>id</th>\n",
       "      <th>pickups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911210</th>\n",
       "      <td>152.0</td>\n",
       "      <td>2414253</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911211</th>\n",
       "      <td>152.0</td>\n",
       "      <td>2414254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911212</th>\n",
       "      <td>152.0</td>\n",
       "      <td>2414267</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911213</th>\n",
       "      <td>152.0</td>\n",
       "      <td>2414268</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35911215</th>\n",
       "      <td>152.0</td>\n",
       "      <td>2414372</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9239928 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            day       id  pickups\n",
       "0           1.0        0     19.0\n",
       "1           1.0        1     18.0\n",
       "2           1.0        2     18.0\n",
       "3           1.0        3     17.0\n",
       "4           1.0        4     13.0\n",
       "...         ...      ...      ...\n",
       "35911210  152.0  2414253      0.0\n",
       "35911211  152.0  2414254      0.0\n",
       "35911212  152.0  2414267      0.0\n",
       "35911213  152.0  2414268      0.0\n",
       "35911215  152.0  2414372      0.0\n",
       "\n",
       "[9239928 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickups_df = pd.read_csv('data/TLC_daily.csv')\n",
    "pickups_df = pickups_df[pickups_df['id'].isin(obs_nodes_set)]\n",
    "pickups_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 282983 entries, 0 to 282982\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   olng    282983 non-null  float64\n",
      " 1   olat    282983 non-null  float64\n",
      " 2   dlng    282983 non-null  float64\n",
      " 3   dlat    282983 non-null  float64\n",
      " 4   oid     282983 non-null  int64  \n",
      " 5   did     282983 non-null  int64  \n",
      "dtypes: float64(4), int64(2)\n",
      "memory usage: 13.0 MB\n"
     ]
    }
   ],
   "source": [
    "edges_df = pd.read_csv('data/road_intersection_edges.csv')\n",
    "edges_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8335/238814031.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  obs_edges_df['dist'] = obs_edges_df.apply(lambda x: haversine(x['olng'], x['olat'], x['dlng'], x['dlat']), axis=1).astype(float)\n"
     ]
    }
   ],
   "source": [
    "obs_edges_df = edges_df[edges_df.oid.isin(obs_nodes_set) & edges_df.did.isin(obs_nodes_set)]\n",
    "# computing edges weights in km\n",
    "obs_edges_df['dist'] = obs_edges_df.apply(lambda x: haversine(x['olng'], x['olat'], x['dlng'], x['dlat']), axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60789, 75647)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_graph_from_df(nodes_df, edges_df, name='TLC', directed=False):\n",
    "    G = nx.Graph(directed=directed)\n",
    "    G.graph['Name'] = name\n",
    "\n",
    "    G.add_nodes_from(nodes_df.set_index('id').to_dict('index').items())\n",
    "    G.add_nodes_from((n, {'id': n}) for n in G.nodes())\n",
    "\n",
    "    G.add_edges_from(nx.from_pandas_edgelist(edges_df, 'oid', 'did', ['dist']).edges(data=True))\n",
    "\n",
    "    return G\n",
    "\n",
    "G = make_graph_from_df(obs_nodes_df, obs_edges_df)\n",
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search for node embeddings I use node2vec approach. I tried to use network SVD from network-sklearn, but it didn't work well (I got very low scaled vectors with values about 1e-20). node2vec gives more pleasant embeddings in terms of using dot product or cosine similarity. By the way it's not so fast (model trains for 3,5 minutes for graph with 60k vertices and 75k edges with some hyperparameters tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 60789/60789 [00:02<00:00, 21809.00it/s]\n",
      "Generating walks (CPU: 1): 100%|██████████| 3/3 [00:18<00:00,  6.29s/it]\n",
      "Generating walks (CPU: 3): 100%|██████████| 2/2 [00:12<00:00,  6.36s/it]\n",
      "Generating walks (CPU: 2): 100%|██████████| 3/3 [00:19<00:00,  6.58s/it]\n",
      "Generating walks (CPU: 4): 100%|██████████| 2/2 [00:12<00:00,  6.38s/it]\n"
     ]
    }
   ],
   "source": [
    "embedder = Node2Vec(G, dimensions=128, walk_length=30, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "model = embedder.fit(window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 24)\n",
      "(0, 350192)\n",
      "(1, 2)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "for idx, e in enumerate(G.edges()):\n",
    "    if idx == 5:\n",
    "        break\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('350192', 0.9818602800369263),\n",
       " ('1', 0.9805067181587219),\n",
       " ('24', 0.9659330248832703),\n",
       " ('2', 0.9506922960281372),\n",
       " ('200921', 0.93857741355896),\n",
       " ('350191', 0.9364938139915466),\n",
       " ('3', 0.9200775027275085),\n",
       " ('200923', 0.9051973223686218),\n",
       " ('332388', 0.8834402561187744),\n",
       " ('4', 0.8787604570388794)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "# join embeddings with corresponding nodes (as x feature)\n",
    "for idx, node in enumerate(G.nodes()):\n",
    "    G.add_node(int(node), x=model.wv[str(node)].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60789"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Torch dataset. Used especcially for batch training.\n",
    "\n",
    "class DayObservationsDataset(Dataset):\n",
    "    def __init__(self, pickups_df: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pickups_df['id'].to_numpy()\n",
    "        self.targets = pickups_df['pickups'].to_numpy()\n",
    "        self.observed_nodes = set(np.unique(self.data))\n",
    "\n",
    "        self.node_to_target = pickups_df.set_index('id')['pickups'].to_dict()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "    def get_observation_by_node(self, node):\n",
    "        return self.node_to_target[node]\n",
    "\n",
    "    def get_observed_nodes(self):\n",
    "        return self.observed_nodes\n",
    "\n",
    "\n",
    "def make_dataset_by_day(pickups_df, day):\n",
    "    df = pickups_df[pickups_df['day'].astype('int') == day].copy()\n",
    "    df.drop('day', axis=1, inplace=True)\n",
    "    return DayObservationsDataset(df)\n",
    "\n",
    "\n",
    "ds = make_dataset_by_day(pickups_df, 20)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29786 12766 18237\n"
     ]
    }
   ],
   "source": [
    "# train-val-test split\n",
    "\n",
    "np.random.seed(228)\n",
    "\n",
    "indices = list(range(len(ds)))\n",
    "\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.3)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.3)\n",
    "print(len(train_indices), len(val_indices), len(test_indices))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(ds, batch_size=128, sampler=train_sampler)\n",
    "val_loader = DataLoader(ds, batch_size=len(val_sampler.indices), sampler=val_sampler)\n",
    "test_loader = DataLoader(ds, batch_size=len(test_sampler.indices), sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[60789, 128], edge_index=[2, 151294], lng=[60789], lat=[60789], id=[60789], dist=[151294])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pytorch geometric Data object. For now used only for storing node embedding. \n",
    "# Supposed to be used in the future for obtaining node embeddings.\n",
    "pyg_graph = from_networkx(G)\n",
    "pyg_graph.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_fn(dists, lamb):\n",
    "    return torch.exp(-lamb * dists)\n",
    "\n",
    "\n",
    "class Estimator(nn.Module):\n",
    "    def __init__(self, pyg_graph: pyg.data.Data, nodes_df: pd.DataFrame, observations: Tuple[List, List]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.g = pyg_graph\n",
    "        self.nodes_df = nodes_df\n",
    "        self.obs_nodes = observations[0]\n",
    "        self.obs_targets = observations[1]\n",
    "\n",
    "        self.NEIGHBORS_NUM = 15\n",
    "        \n",
    "        # dicts for fast indexing\n",
    "        self.node_to_idx = np.vectorize(dict(zip(self.nodes_df.id.values, itertools.count())).get)\n",
    "        self.node_to_gidx = np.vectorize(dict(zip(self.g.id.detach().cpu().numpy(), range(len(self.g.id)))).get)\n",
    "        \n",
    "        self.neighbors = NearestNeighbors(n_neighbors=self.NEIGHBORS_NUM, metric='haversine')\n",
    "        self.obs_nodes_locs = self.nodes_df.iloc[self.node_to_idx(self.obs_nodes)]\n",
    "        self.neighbors.fit(self.obs_nodes_locs[['lat', 'lng']].values)\n",
    "\n",
    "        self.k = nn.Parameter(torch.rand(1))\n",
    "        # self.k = torch.tensor([1.0])\n",
    "        self.lambda_1 = nn.Parameter(torch.rand(1))\n",
    "        self.lambda_2 = nn.Parameter(torch.rand(1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # getting nearest observed nodes\n",
    "        dists, indices = self.neighbors.kneighbors(self.nodes_df.iloc[self.node_to_idx(X.detach().cpu())][['lat', 'lng']].values)\n",
    "        # coverting dists to meters\n",
    "        dists = dists * 6371 * 1000\n",
    "\n",
    "        # skipping loc by itself\n",
    "        if self.training:\n",
    "            dists, indices = dists[:, 1:], indices[:, 1:]\n",
    "\n",
    "        observations = self.obs_targets[indices]\n",
    "\n",
    "        dists, observations = torch.as_tensor(dists).to(device), torch.as_tensor(observations).to(device)\n",
    "\n",
    "        # finding corresponding node embedding of neighbors\n",
    "        neighbors_indices = self.node_to_gidx(self.obs_nodes[indices])\n",
    "        neighbors_embeds = self.g.x[neighbors_indices.reshape(-1)].reshape(*neighbors_indices.shape, -1)\n",
    "\n",
    "        # computing similarities between node ans its neighbors\n",
    "        X_embeds = self.g.x[self.node_to_gidx(X.detach().cpu())]\n",
    "        similarities = nn.functional.cosine_similarity(X_embeds[:, None], neighbors_embeds, dim=2)\n",
    "\n",
    "        dist_weights = weight_fn(dists, self.lambda_1)\n",
    "        simi_weights = weight_fn(similarities, self.lambda_2)\n",
    "\n",
    "        # sum normalizization\n",
    "        dist_weights = nn.functional.normalize(dist_weights, p=1)\n",
    "        simi_weights = nn.functional.normalize(simi_weights, p=1)\n",
    "\n",
    "        att_weights = self.k * dist_weights + (1 - self.k) * simi_weights\n",
    "\n",
    "        # interpolation\n",
    "        result = torch.sum(att_weights.mul(observations), dim=-1)\n",
    "\n",
    "        return result\n",
    "\n",
    "estimator = Estimator(pyg_graph, obs_nodes_df, ds[train_indices]).to(device)\n",
    "# kek = next(iter(train_loader))\n",
    "# estimator(kek[0])[:20], kek[1][:20] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I tried MSE and Huber losses, and I got very vary results (Huber(20) ~ 40-60, MSE ~ 200). -> maybe there are a lot of outliers in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 101.5078, Val loss: 68.1226, Val R2: 0.8927\n",
      "Epoch 5, Loss: 62.5840, Val loss: 62.9940, Val R2: 0.8986\n",
      "Epoch 10, Loss: 62.2805, Val loss: 63.5245, Val R2: 0.8922\n",
      "Epoch 15, Loss: 65.8209, Val loss: 69.6374, Val R2: 0.8687\n",
      "Epoch 20, Loss: 62.0570, Val loss: 63.3509, Val R2: 0.8924\n",
      "Epoch 25, Loss: 61.8861, Val loss: 63.3530, Val R2: 0.8923\n",
      "Epoch 30, Loss: 61.9191, Val loss: 63.2877, Val R2: 0.8928\n",
      "k Parameter containing:\n",
      "tensor([0.8897], device='cuda:0', requires_grad=True)\n",
      "lambda_1 Parameter containing:\n",
      "tensor([0.1496], device='cuda:0', requires_grad=True)\n",
      "lambda_2 Parameter containing:\n",
      "tensor([-7.6407], device='cuda:0', requires_grad=True)\n",
      "Test loss: 59.35342082984052, test score: 0.8628653999248925\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.HuberLoss(delta=20).to(device)\n",
    "# loss_fn = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(estimator.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10, gamma=0.5)\n",
    "\n",
    "\n",
    "def calc_score(pred, actual):\n",
    "    return r2_score(actual, pred)\n",
    "\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    scores = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in loader:\n",
    "            X_gpu = X.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            out = model(X_gpu)\n",
    "            scores.append(calc_score(out.detach().cpu(), y))\n",
    "            loss = loss_fn(out, y_gpu)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(loader), np.mean(scores)\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, loss_fn, optimizer, scheduler=None, num_epochs=30):\n",
    "    losses = []\n",
    "    test_scores = []\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for i_step, (X, y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            X_gpu = X.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            out = model(X_gpu)\n",
    "            loss = loss_fn(out, y_gpu)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        total_loss /= len(train_loader)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            val_loss, score = test(model, val_loader)\n",
    "            test_scores.append(score)\n",
    "            print(f'Epoch {epoch}, Loss: {losses[-1]:.4f}, Val loss: {val_loss:.4f}, Val R2: {test_scores[-1]:.4f}')\n",
    "\n",
    "train(estimator, train_loader, val_loader, loss_fn, optimizer, scheduler)\n",
    "\n",
    "for name, param in estimator.named_parameters():\n",
    "    print(name, param)\n",
    "\n",
    "test_loss, test_score = test(estimator, test_loader)\n",
    "print(f'Test loss: {test_loss}, test score: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30452e0fb0b877c71442cfddf3db9e1b032e1699292a3dd400d9a1b61508e43d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('traffic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
